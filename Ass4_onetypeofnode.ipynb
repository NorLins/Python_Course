{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e465df9-d157-4b4e-88eb-3bdbf25ff0b9",
   "metadata": {},
   "source": [
    "# *MoMA's* artists and their collaboration network\n",
    "## Data project for \"2021W 136010-1 Introduction to DH Tools and Methods\". \n",
    "##### Nora Linser (01315533) 2022-01-23\n",
    "\n",
    "# Introduction\n",
    "*The Museum of Modern Art* in New York provides two datasets on *github*, one containing the artists that are represented in their collections and the other one the artworks itselt. \n",
    "Ithe artworks themselves. \n",
    "I will use the datasets, particularly the artwork dataset, to conduct a social network analysis of the artists represented in the *MoMA* collections. In doing so, I will assume that there is a social connection between the artists who collaborated in the creation of an artwork. \n",
    "\n",
    "# Research question and objective\n",
    "The goal of this project is to examine the dataset and create a network analysis based on the shared authorship of artworks by artists. \n",
    "A graph object will be created and centrality measures (Betwenness Centrality, Closeness Centrality, Degree distribution) will be calculated and displayed in plots (histograms and graphs). The size of the nodes in the respective diagrams should depend on the displayed centrality measures. Based on one of the centrality measures, a subgraph containing only the 100 most important nodes should be computed. A nice representation of this subgraph is the goal of the network investigation, where also some of the node attributes like gender or origin should be reflected (<font color =darkred>this part is not finished yet, but will be fulfilled in the Final Assignment</font>). \n",
    "\n",
    "# Source\n",
    "*MoMA* notes in the README file on Github that some of the data is not complete and that other information is not \"approved by the curator.\" They also make it clear that use of the data is at the user's risk. \n",
    "MoMA planned to update the records on Github monthly, but the last update was done in January 2021. This is also the version (1.62) that I downloaded to use for this project.\n",
    "\n",
    "## Reference:  \n",
    "- Data collected by: Moma – Museum of modern Art.\n",
    "- Dataset: 15,222 records. Encoding: UTF-8. \n",
    "- Data format: .csv and JSON.\n",
    "- Data distribution via [Github](https://github.com/MuseumofModernArt/collection) by the users John Halderman and momadm. \n",
    "- Licensing: CC0 License.\n",
    "- Digital object identifier DOI: 10.5281/zenodo.4408594\n",
    "- [Presidential URL](https://zenodo.org/record/4408594#.YcGKvC1h1pR)\n",
    "- Version: v1.62, release date: 2021/01/01\n",
    "- Day and time of download: 2021/12/21 12:43 PM \n",
    "\n",
    "## Short citation:\n",
    "Moma – Museum of Modern Art (2021/01/01), Artists (Data file in CSV Format). Doi: 10.5281/zenodo.4408594. Retrieved from https://github.com/MuseumofModernArt/collection  \n",
    "\n",
    "Moma – Museum of Modern Art (2021/01/01), Artwork (Data file in CSV Format). Doi: 10.5281/zenodo.4408594. Retrieved from https://github.com/MuseumofModernArt/collection \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f806e4-6865-4df3-913c-50aa61a73f98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Importing the dataset and getting a first overview\n",
    "Setting up the working environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12af78-d55e-421c-8e1e-f52ebe1833a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the working environment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bad2df-15b4-476b-a708-c01a85a266ec",
   "metadata": {},
   "source": [
    "Importing the files and displaying the first overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25fb45-08cd-4f6e-9cb2-01e152cab989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the file downloaded from github\n",
    "artworksAll = pd.read_csv(\"/Users/linsernora/Pyhton_Course/Python_CourseNorLins/MoMAartworks/Artworks.csv\")\n",
    "artworksAll.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b945f-4197-4463-b48e-16337a4f957b",
   "metadata": {},
   "source": [
    "My first attemt to find out if there are objects listed with more than one artist in the Artist column was no very helpful.\n",
    "I though my just printing a couple of rows I might get an impression of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd1f47-67ff-4b50-a3a3-0787eb96d40d",
   "metadata": {},
   "source": [
    "Getting all the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea616a-bd3f-4739-8e8b-a57ced5df7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listing all the column headers of the dataset: \n",
    "list(artworksAll.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed56a13-cfc3-4e41-9689-45916c8e6a3e",
   "metadata": {},
   "source": [
    "## Finding multiple artist occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0ddab-0e38-482d-9148-cd90c754f90e",
   "metadata": {},
   "source": [
    "I tried to find out if there are rows with more than on artist by using the .isin() method. \n",
    "At first I though that the given result would suggest that there are no commas in the column. \n",
    "To use this approach I would have needed to take further steps with this result and to find out in which columns the result is \"True\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2b814-5dfc-4e63-bed5-2dd5e147b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if there are rows with multiple artists in the Artist column\n",
    "artists = artworksAll[\"Artist\"]\n",
    "multiple = artists.isin([\",\"])\n",
    "multiple.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20d6f9-ee93-4cb6-8a45-b6b584be05f6",
   "metadata": {},
   "source": [
    "The next apprach was more useful. Subsetting the rows that contain a \",\" in the \"Artist\" column and assigning it to a new DataFrame *multipleArtists*.\n",
    "The .info() methods shows that there are 8059 entries in the dataset where there is more than one artist mentioned in the \"Artist\" column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebbb0e-ef6c-4599-a174-90787b76df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting the rows with more than one artist. \n",
    "multipleArtists = artworksAll[artworksAll[\"Artist\"].str.contains(\",\")==True]\n",
    "multipleArtists.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21a982-05ca-4e41-9b22-834dbf3277d2",
   "metadata": {},
   "source": [
    "Before geoing any further I wanted to check if the dataset is restricted to show one object per row. As the result shows, there are no duplicate \"ObjectID\"'s in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a9f0f-1462-4699-b36d-a654954829f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if there are objectsIds mentioned more than once: \n",
    "objectIds = artworksAll[\"ObjectID\"]\n",
    "artworksAll[objectIds.isin(objectIds[objectIds.duplicated()])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4df2f2-86b1-4ea8-85f0-720803757d06",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "Reducing the columns that are not needed for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a031f-4479-42fe-bfc0-4695a09d7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the dataframe, only keeping the columns that are needed: \n",
    "multipleArtists = multipleArtists[[\"Title\", \"Artist\", \"ConstituentID\", \"ObjectID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3903e80-b70d-472a-ade2-a55a34f1bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if it worked: \n",
    "multipleArtists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19582d-cb5c-4836-aac8-7ba66bb6b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "multipleArtists.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46f410-4bb3-410f-a628-d227f181f2f7",
   "metadata": {},
   "source": [
    "### Splitting up the values\n",
    "Next step is to split up the values from the columns \"Artist\", \"Constitutent ID\" and \"Title\" into separate rows. \n",
    "So that each artist occurrence is mentioned in its own row. The data in the columns \"Title\" and \"ObjektID\" needs to be copied to the new observations. \n",
    "\n",
    "With a little help of *stackoverflow* I created the following approach of stacking and unstacking that provides me with the desired output. I created a new dataframe with the result called *singleArtist*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7cec2-ad83-4816-ae79-f192dfccaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking and unstacking the data to move every artist-occurrence from the \"Artist\" column into separate lines. \n",
    "#Without loosing the data that needs to be copied. \n",
    "singleArtist = (multipleArtists.set_index(['Title', 'ObjectID'])\n",
    "   .stack()\n",
    "   .str.split(',', expand=True)\n",
    "   .stack()\n",
    "   .unstack(-2)\n",
    "   .reset_index(-1, drop=True)\n",
    "   .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b129e-bc96-488c-96e1-5da7ec0cf187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling singleArtist to see if it worked: \n",
    "singleArtist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5659f9-7e27-4691-a81e-cf711a5ff8b8",
   "metadata": {},
   "source": [
    "Investing if the first rows do not hold any data in the Title column or if something went wrong there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef595f-633a-44b5-9996-fdd078a0443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chechking if the object does not have a title of if I made I mistake: \n",
    "multipleArtists[multipleArtists[\"ObjectID\"] == 136435]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79202f2c-9b8d-4f12-a2c1-80ab089c53bd",
   "metadata": {},
   "source": [
    "The artwork does not hold any data as Titel.\n",
    "Making sure the stacking worked and also the constiutent IDs were split up accordingly to the artist names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adede72f-c415-4d47-b144-dc7f4065a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if I split up the Constitutent IDs correctly\n",
    "singleArtist[singleArtist[\"ObjectID\"] == 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587f17a-4d02-466f-94e5-f958d6122199",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleArtist[singleArtist[\"Artist\"] == \"Peter Eisenman\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80fa0d-dadf-40e8-bdca-b1af8be7b183",
   "metadata": {},
   "source": [
    "The multiple occurrences in the \"Artist\"Column are split up into separate lines, the metadata was copied in to the lines as wanted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c27562-4e3c-46c3-899a-cb930ef00b76",
   "metadata": {},
   "source": [
    "Before adding the additional rows for each artist, the dataframe contained 'r: mutipleArtists.count()' 8059 elements. Now, after splitting up the multiple occurrences, the dataframe holds 24900 elements. \n",
    "This might be to big to comfortable work with in my environment, but I will try it out. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69dcf6-e1ab-4fd5-a97f-bad9c93337a5",
   "metadata": {},
   "source": [
    "## Creating a Graph object\n",
    "To investigate the network and to be able to draw graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4254c-8055-42a5-baa6-d3535e4ac8a2",
   "metadata": {},
   "source": [
    "Creating a nodelist with unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8bd6e-780a-411c-87ed-2c0ec0f56133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a unique list of all the possible nodes, I might need that later.\n",
    "objectEdges = singleArtist[\"ObjectID\"].unique()\n",
    "objectEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43982b76-212c-4316-9709-507fb5d07174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many objects are we dealing with in the dataset singleArtist?\n",
    "print(\"Count of objectnodes in the dataframe singleArtist:\", len(objectnodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb521189-8cc7-45c7-80ae-b69b9a3b9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a unique list of nodes for the ArtistID's\n",
    "artistnodes = singleArtist[\"ConstituentID\"].unique()\n",
    "#how many unique artists are in the singleArtist dataframe?\n",
    "print(\"Count of artistnodes in the dataframe singleArtist:\", len(artistnodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29652e9e-9b49-4f47-a7b9-3c27b5bc68a1",
   "metadata": {},
   "source": [
    "Importing networkx and matplotlib packages for further investigation and vizualisation of the social network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770db9a1-80e0-4157-92f8-9cfa6cce2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import Graph as NXGraph\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df3ac1-0edd-4624-8d3d-b4b206b08169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty graph\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc87ea8-45df-413d-847d-d3b7ab503c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an edgelist containging only the ObjectIDs and the ConstitutentIDs. might be useful later.\n",
    "edgelist = multipleArtists[[\"ObjectID\", \"ConstituentID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3673a-aeb7-4094-ae34-ca419abdd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the edges: \n",
    "G= nx.from_pandas_edgelist(edgelist, source=\"ObjectID\", target=\"ConstituentID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba41470-c099-46fd-b350-95ae52534561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't run again if not needed, takes a long time. \n",
    "#nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f2c09-2382-4f69-9205-dfed10bd2f44",
   "metadata": {},
   "source": [
    "Running this takes up to 10 minutes. To comfortably work with the dataset, I need to reduce the size.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902773a-34e3-4af9-bc78-a5e3abe466d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Reducing the size fo the graph object\n",
    "The graph object holding the complete data needs to be reduced, it slows down my computer to much. \n",
    "For this project I will limit the dataset based on the aquisition date of the object. \n",
    "\n",
    "Only the objects that where arquired between the years 1980 and 2000 stay in the dataset. To do this I subset the original dataframe with a slice on the \"DateAquired\" column. \n",
    "To do so I set the \"DateAcquired\" column as index and sort the dataframe based on that values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2b7d4-69b5-4d8d-937e-3b0b8be8ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the DateAcquired Colum as index and sorting it in ascending order. \n",
    "artworks_ind = artworksAll.set_index(\"DateAcquired\").sort_index()\n",
    "artworks_ind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebf88f-4a82-48b6-9e03-166f13804d02",
   "metadata": {},
   "source": [
    "Next I slice the df brased on the timeframe between 1980 and 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2926570-4ebf-45aa-b4a4-566d0067c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing the DataFrame so we only keep objects with an aquisition date (\"DataAquired\") between 1980 and 2000: \n",
    "artworks_sliced1 = artworks_ind.loc[\"1980-01-01\":\"2000-01-01\"]\n",
    "#getting the info on the new dataset\n",
    "artworks_sliced1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57429f-3743-40b0-b818-876053ebab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The new dataframe contains\", len(artworks_sliced1), \"elements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddce2cd-55b1-441e-af54-98c60f8118ae",
   "metadata": {},
   "source": [
    "This slice holds 21682 elements and is still to big. I shorten the timeframe again to only work with objects that were aquired between the years 1980 and 1990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5d9eb-de8c-489d-9cdc-774c6db86717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the slice to the timeframe 1980 until 1990\n",
    "artworks_sliced = artworks_ind.loc[\"1980-01-01\":\"1990-01-01\"]\n",
    "artworks_sliced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e463e2-fb04-4f43-95f1-96e4c1d11421",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The sliced dataframe contains\", len(artworks_sliced), \"elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8912368-66d1-4331-a564-72fc05a6445f",
   "metadata": {},
   "source": [
    "With this dataset of 10187 lines I repeat the steps from above.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b0b522-5f8e-40d6-baa9-1d97d693fa91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Prepping the smaller dataset\n",
    "Repeating the steps from above: Subsetting the rows with multiple artists, removing unnecessary columns, restacking the data so every artist is mentioned in its own row, adding columns with ID an prefix \"artist\" or \"object\" repectiviley. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b9c60-1eb3-4a17-ba6e-bda296c73276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting the rows with more than one artist. \n",
    "multiArtists = artworks_sliced[artworks_sliced[\"Artist\"].str.contains(\",\")==True]\n",
    "multiArtists.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b284138-8c53-4338-b1ac-337477e646e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keeping the columns that are needed: \n",
    "multiArtists = multiArtists[[\"Title\", \"Artist\", \"ConstituentID\", \"ObjectID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7129c3-aa29-4701-934f-29243bb24524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the multiple values and adding them as new rows:\n",
    "single_Artist = (multiArtists.set_index(['Title', 'ObjectID'])\n",
    "   .stack()\n",
    "   .str.split(',', expand=True)\n",
    "   .stack()\n",
    "   .unstack(-2)\n",
    "   .reset_index(-1, drop=True)\n",
    "   .reset_index()\n",
    ")\n",
    "single_Artist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804aaef-2f35-48fc-918a-232a8c149021",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_Artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0297f-dc2e-428f-99f8-1dfe81515d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of elements in the dataframe single_Artist:\", len(single_Artist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda1fe9-5c9f-4166-986c-2215da7c1add",
   "metadata": {},
   "source": [
    "This leaves us with 1559 entries, a managable size for this social network project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d29990-a9be-4735-af35-3cc9c9a7c692",
   "metadata": {},
   "source": [
    "## Adding prefixes to the Ids to distinguish them: \n",
    "Before I go any further I am adding new columns to the dataset where I store acombination of the ObjectID and the ConstituentId together with the prefixes \"object\" and \"artist\". The numbers alone would not be distinguishable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e945d4-605b-4002-a4d7-df3939c9211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column where the ObjectId has the prefix \"object\"\n",
    "single_Artist[\"ObjectID_unique\"] = \"object\" + single_Artist[\"ObjectID\"].astype(str)\n",
    "single_Artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116761b-2abe-475e-8c40-ece81eb0acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding another new column where the ConstitutentID has the prefix \"artist\"\n",
    "single_Artist[\"ConstituentID_unique\"] = \"artist\" + single_Artist[\"ConstituentID\"].astype(str)\n",
    "single_Artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81384fbc-a90b-40b7-8ff9-c1043fd0ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the white spaces:\n",
    "single_Artist[\"ConstituentID_unique\"] = single_Artist[\"ConstituentID_unique\"].str.replace(' ', '')\n",
    "single_Artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdc478-f5dd-495f-aadc-d75f9dcd4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make sure there are no whitespaces in the \"ObjectID_unique\" column\n",
    "single_Artist[\"ObjectID_unique\"] = single_Artist[\"ObjectID_unique\"].str.replace(' ', '')\n",
    "single_Artist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac443f-31c7-4bb4-b301-4c556e7aefdc",
   "metadata": {},
   "source": [
    "With the cleaned up data I count the unique ObjetIds and unique ConstitutenIDs again. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4a730-252a-45a3-85a0-e8f7be0d859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting the unique artist Ids in the new DataFrame: \n",
    "artist_Ids = single_Artist[\"ConstituentID_unique\"].unique()\n",
    "print(\"There are\", len(artist_Ids), \"unique artists mentioned in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5782ec-7038-4c3f-92a3-138e2a96e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting the unique object Ids in the new DataFrame: \n",
    "object_Ids = single_Artist[\"ObjectID_unique\"].unique()\n",
    "print(\"There are\", len(object_Ids), \"unique objects mentioned in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d396d958-2f75-4c95-bbf4-b5cc317a0038",
   "metadata": {},
   "source": [
    "The new smaller Dataframes contains 575 artists and 615 different objects. Lets find out how they are connected to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a106fba-1516-495a-b2a5-fbc5fc9bb456",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adding node attributes\n",
    "To do so we need to get the data from the artists dataset. We will then compute different colours for the gender values in the dataset. This column will than be appended to the graph object where it will be used to plot the node color accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e285c6e-8f26-4b7a-bafc-9041b70f5a42",
   "metadata": {
    "tags": []
   },
   "source": [
    "Getting the gender data from the artists dataset, to have an unique identifyer we need to adapt the ConstitutentID like we did for the graph object and add \"artists\" to the values as prefix. We allso remove unwanted whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ccbd9-82da-4e33-82a6-41f457071a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the \"ConstitutentID_unique\" column to the artis df, so that we have a unique identifier.\n",
    "artists_complete[\"ConstituentID_unique\"] = \"artist\" + artists_complete[\"ConstituentID\"].astype(str)\n",
    "#remove the whitespaces\n",
    "artists_complete[\"ConstituentID_unique\"] = artists_complete[\"ConstituentID_unique\"].str.replace('_', '')\n",
    "artists_complete.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6075721-a9ab-4c30-acdb-77a6c58d79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the count of the unique values\n",
    "len(artists_complete[\"Gender\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97887e71-f042-4961-9d43-4083d26d2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the unique values\n",
    "artists_complete[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790f712-8ca0-403f-8ebe-16f2fce4647c",
   "metadata": {},
   "source": [
    "We need to unify the gender entries to four unique values: \"non-binary\", \"male\", \"female\", \"nan\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46ce14-72ed-44b4-b7c0-f9a00fd7b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the whitespaces:\n",
    "artists_complete[\"Gender\"] = artists_complete[\"Gender\"].str.replace('Male', 'male')\n",
    "artists_complete[\"Gender\"] = artists_complete[\"Gender\"].str.replace('Female', 'female')\n",
    "artists_complete[\"Gender\"] = artists_complete[\"Gender\"].str.replace('Non-Binary', 'non-binary')\n",
    "artists_complete[\"Gender\"] = artists_complete[\"Gender\"].str.replace('Non-binary', 'non-binary')\n",
    "#checking how many unique values we have now:\n",
    "artists_complete[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed10741-fb9e-4039-83e0-6018dd3b9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if we now have 4 unique values.\n",
    "len(artists_complete[\"Gender\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9055ef-400a-46f2-bffb-d0a0e70ffe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NaN values with the value \"notspecified\"\n",
    "artists_complete[\"Gender\"] = artists_complete[\"Gender\"].fillna(\"notspecified\")\n",
    "artists_complete[\"Gender\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe658ef3-b257-4190-af13-7b0c281e0e39",
   "metadata": {},
   "source": [
    "We now use the numpy package to add a new column \"GenderColour\" to the dataframe artists_complete. The colum stores colours according to one of the 4 gender values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7aab8-c0ab-4265-8553-07badb001700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.dataquest.io/blog/tutorial-add-column-pandas-dataframe-based-on-if-else-condition/ \n",
    "#create list of conditions\n",
    "import numpy as np\n",
    "conditions = [\n",
    "    (artists_complete[\"Gender\"] == \"male\"), \n",
    "    (artists_complete[\"Gender\"] == \"female\"), \n",
    "    (artists_complete[\"Gender\"] == \"non-binary\"),\n",
    "    (artists_complete[\"Gender\"] == \"notspecified\")\n",
    "    #(artists_complete[\"Gender\"] == \"NaN\")\n",
    "    ]\n",
    "#create a list of the values we want to assign for each condition (order is important)\n",
    "values = [\"green\", \"blue\", \"red\", \"gray\"]\n",
    "#create a new column and use np.select to assign values to it using our lists as arguments\n",
    "artists_complete[\"GenderColour\"] = np.select(conditions,values)\n",
    "#inspect the df\n",
    "artists_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e73b0a-f873-4b40-a02a-0d3b96384baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gender_nodes = nx.get_node_attributes(Gnew, \"GenderColour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c34824-fd29-4114-88df-a96774bdf924",
   "metadata": {},
   "source": [
    "We also need to add a colour to the objects. So that all nodes will have a colour attribute.  Here all get the same colour assign to them, whichs makes it easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdd31a-b636-46d8-b2c1-e4c3d096f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the file. \n",
    "#Import the file from github\n",
    "artists_complete = pd.read_csv(\"/Users/linsernora/Pyhton_Course/Python_CourseNorLins/MoMAartworks/Artists.csv\")\n",
    "artists_complete.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd3fc6-66ac-41de-be2a-35d43ed78b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column to the dataframe with the colour the nodes should be displayed in the graph\n",
    "single_Artist[\"object_colour\"] = \"lightgray\"\n",
    "single_Artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d1bf4-5fd0-49dc-9204-ba457e38d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the column to the df that was used to create the dataframe. \n",
    "#get all the nodes with prefix \"artists\",  add the node attribute \"GenderColour\" and set it to \"ligthgray\"\n",
    "\n",
    "#getting the nodes that don't hold the attribute \"GenderColour\"\n",
    "\n",
    "#list(Gnew.nodes.data(\"GenderColour\"))\n",
    "\n",
    "\n",
    "#we start with one attripute (gender): \n",
    "#object_colour = single_Artist[[\"ObjectID_unique\", \"object_colour\"]]\n",
    "#setting the index\n",
    "#object_colour_dic = object_colour.set_index(\"ObjectID_unique\").T.to_dict(\"list\")\n",
    "#adding the \"gender\"data to the node attributes\n",
    "#nx.set_node_attributes(Gnew, object_colour_dic, \"GenderColour\")\n",
    "\n",
    "#Gnew.nodes(data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69a10f9-1589-474d-b9fd-6bce88c4b2cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merging the datasets. \n",
    "\n",
    "I will now add metadata on the artist entities from the second dataset MoMA provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f2aa5-70d0-43b6-b0ac-408ae28553d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the file. \n",
    "#Import the file from github\n",
    "artists_complete = pd.read_csv(\"/Users/linsernora/Pyhton_Course/Python_CourseNorLins/MoMAartworks/Artists.csv\")\n",
    "artists_complete.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af86a9-d209-4616-b819-5f39a6a1780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_Artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68363aa1-64f8-4bce-8156-06364a3b880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to remeber the size of the single_Artist Dateframe: \n",
    "single_Artist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efc508-098b-4680-b863-ec45f47a6a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the metadata based on the ConstituentID (as unique value in both dfs) \n",
    "#at first try I received the error \"You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat\". \n",
    "#So I convert the ConstituentID vlaues to type text (since there is also \"Nan\" in there).\n",
    "\n",
    "single_Artist[\"ConstituentID\"]=single_Artist[\"ConstituentID\"].astype(str)\n",
    "artists_complete[\"ConstituentID\"]=artists_complete[\"ConstituentID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd435a-0809-4382-9f96-c7a3c22d8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the two dataframes based on the ConstituentID column\n",
    "\n",
    "single_Artistextended = pd.merge(single_Artist, artists_complete, on=\"ConstituentID\", how = \"left\")\n",
    "single_Artistextended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a3275-a9ce-4473-8a8c-b355142ffe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the df and making sure only columns where added: \n",
    "single_Artistextended.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49bd165-b6f4-4da2-bb7f-efac38dd2bb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating graph object \n",
    "With the smaller dataframe a new graph object is created (Gnew).  \n",
    "\n",
    "The graph is set up as undirected. Since there is no direction in the relation between artists and objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd00cc7-f64b-47d2-abeb-e438e65b33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate an empty undirected graph\n",
    "Gnew = nx.Graph()\n",
    "type(Gnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c32a4c-fc6f-40b4-b3b4-4be44b2c0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the edges to the graph. I am setting the unique object Id columns as the source and the unique artist Ids as the target.\n",
    "Gnew= nx.from_pandas_edgelist(single_Artistextended, source=\"ObjectID_unique\", target=\"ConstituentID_unique\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede4335-6b69-4e0a-b1f7-1373e966acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_node_attributes() takes a dictionary as input. To assign multiple attriputes to the nodes at once, we have to create a dictionary of dictionaries. \n",
    "#the outer dictionary represents the nodes, the inner the keys korresponding to the attributes. \n",
    "#good thing: nodes that are not in the graph are ignored. \n",
    "\n",
    "#we start with one attripute (gender): \n",
    "artists_gender= artists_complete[[\"ConstituentID_unique\", \"GenderColour\"]]\n",
    "#setting the index\n",
    "artists_gender_dic = artists_gender.set_index(\"ConstituentID_unique\").T.to_dict(\"list\")\n",
    "#adding the \"gender\"data to the node attributes\n",
    "nx.set_node_attributes(Gnew, artists_gender_dic, \"GenderColour\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247d5ab-fa65-4226-a475-2b0f0e4d530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing the first graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5c13e-85cf-438a-b602-85fed150fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the first graph without any specifications: \n",
    "nx.draw(Gnew)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357ff77-cf82-4955-9a65-367b6cf649e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot graph T with the node colour based on the gender. \n",
    "#plotting T with node_size depending on betweenness centrality\n",
    "npos = nx.spring_layout(Gnew, scale=1)\n",
    "fig = plt.figure(1, figsize=(20,20))\n",
    "gendercolours = [nx.get_node_attributes(Gnew, \"GenderColour\")[g] for g in Gnew.nodes()]\n",
    "nx.draw(Gnew, pos=npos, \n",
    "        node_size=[v * 10000 for v in between_centrality_T.values()], \n",
    "        #also adding labels\n",
    "        with_labels=True,\n",
    "        node_color=gendercolours,\n",
    "        #node_color = [nx.get_node_attributes(Gnew,'GenderColour')[g] for g in Gnew.nodes()], \n",
    "        edge_color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603c9af-1291-4991-a61c-eb99b59a3a0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Refining the plots\n",
    "With setting some arguments the graph plot can be refined and made better readable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f85726-efd8-4acf-81d2-13d9498bc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the same graph but with some arguments \n",
    "pos = nx.spring_layout(Gnew, scale=1)\n",
    "fig = plt.figure(1, figsize=(20,20))\n",
    "nx.draw(Gnew, with_labels=False, node_color=\"seagreen\", node_size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1dbf9d-d6f5-43ef-8109-582aa575033c",
   "metadata": {},
   "source": [
    "##### Exploring the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4839c-68d6-40ba-8c5f-205ad53f8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting feeling for the size of the graph \n",
    "#Count of the nodes:\n",
    "print(\"There are\", len(Gnew.nodes()), \"nodes in the network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428b7069-68a6-4b03-a941-17ae6285ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of the edges: \n",
    "print(\"There are\", len(Gnew.edges()), \"edges in the network.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee2f2fd-98ba-4dcf-8f2e-53ab96799008",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Investigating the centrality measure of the network: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7bd502-8057-47c8-89e6-32022043ca58",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Degree centrality\n",
    "Finding the network centrality meassures.\n",
    "Since the network is not directed, we don't need to take in degree and out degree into account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4cf62e-e85b-4c43-a652-eb706d6afa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the degree centrality\n",
    "centrality = nx.degree_centrality(Gnew)\n",
    "#adding the degree_centrality values as node attributes\n",
    "nx.set_node_attributes(Gnew, centrality, \"DegreeCentrality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dcc36-d01e-49fd-943b-a8e920c95cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the degree distribution of the network\n",
    "plt.title(\"Histogram of degree centrality distribution\")\n",
    "plt.hist(list(centrality.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03695665-ae60-4a4c-9205-0c66ec257f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing matplotlib\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742778f3-5276-40bd-ae39-0886e898c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing the graph with nodessizes based on the centrality meassure\n",
    "pos = nx.spring_layout(Gnew, scale=1)\n",
    "fig = plt.figure(1, figsize=(30,30))\n",
    "nx.draw(Gnew, pos=pos, node_size=[v * 1000 for v in centrality.values()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a9687-b262-4a9a-bdd5-b4ba30653897",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Defining the function *find_nodes_with_highest_deg_cent* \n",
    "The function eturns the nodes with the highest degree centrality in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931a191-9c47-4237-b681-033eac354128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining find_nodes_with_highest_deg_cent()\n",
    "def find_nodes_with_highest_deg_cent(G):\n",
    "    '''returns the nodes with the higehst degree centrality in the graph G'''\n",
    "    # Computing the degree centrality of G: deg_cent\n",
    "    deg_cent = nx.degree_centrality(G)\n",
    "    # Computing the maximum degree centrality: max_dc\n",
    "    max_dc = max(list(deg_cent.values()))\n",
    "    nodes = set()\n",
    "    # Iterating over the degree centrality dictionary\n",
    "    for k, v in deg_cent.items():\n",
    "        # Checking if the current value has the maximum degree centrality\n",
    "        if v == max_dc:\n",
    "            # Adding the current node to the set of nodes\n",
    "            nodes.add(k)\n",
    "    return nodes\n",
    "\n",
    "# Find the node(s) that has the highest degree centrality in G: top_dc\n",
    "top_dc = find_nodes_with_highest_deg_cent(Gnew)\n",
    "print(\"Those are the nodes with the highest degree centrality: \", top_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df288a99-230d-4965-820b-5f1cfa3d6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertion statement that checks that the node(s) is/are correctly identified.\n",
    "for node in top_dc:\n",
    "    assert nx.degree_centrality(Gnew)[node] == max(nx.degree_centrality(Gnew).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ec3aa-a61e-4ca5-ae73-4337280eacd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Closeness Centrality: \n",
    "Assuming that important nodes are closer to other nodes. \n",
    "*Closeness centrality* is calucalted as the sum of the path length from the given node to all other nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418aa33a-dcd4-474a-80e7-f7b829546e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the closeness centrality:\n",
    "close_centrality = nx.closeness_centrality(Gnew)\n",
    "#adding the meassure as node attribute to the graph object\n",
    "nx.set_node_attributes(Gnew, centrality, \"ClosenessCentrality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30ba61-527d-49ae-bc2d-6b618467f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the closeness centrality of the network as histogram\n",
    "plt.hist(list(close_centrality.values()))\n",
    "plt.title(\"Histogram on Closeness Centrality Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b539c-f211-45f3-95c0-ef3a72024771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the graph with the node sizes depending on the closeness centrality messure of the nodes.\n",
    "fig = plt.figure(1, figsize=(30,30))\n",
    "nx.draw(Gnew, pos = pos, nodelist=close_centrality.keys(), node_color=\"seagreen\", node_size=[v * 10000 for v in close_centrality.values()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8bd8eb-71b4-4130-9885-34db5eca7775",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Betweenness Centrality: \n",
    "*Betweenness centrality* is computed under the assumption that important nodes connect other nodes. Nodes with a high betweeness cetnrality act like bridges in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b47f5-66c1-4918-91d1-89a6c6087d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the betweeness centrality:\n",
    "bet_centrality = nx.betweenness_centrality(Gnew)\n",
    "#adding the betweeness centrality as node attribute to the graph object: \n",
    "nx.set_node_attributes(Gnew, bet_centrality, \"BetweenessCentrality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62821ce-1461-4bda-a550-ca90e13fbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the degree distribution of the network\n",
    "plt.hist(list(bet_centrality.values()))\n",
    "plt.title(\"Histogramm on the Betweenness Centrality Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc164f60-7d73-4e1c-af09-d1fd91b5bd70",
   "metadata": {},
   "source": [
    "### Finding the Nodes with highest betweenness centrality\n",
    "Defining the function *summary* that profides us with the nodes that have the highest betweeness centrality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525019e0-3124-4aa5-bc4c-a982bbb1334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function summary\n",
    "def summary(G):\n",
    "    '''\n",
    "    Getting the values and nodes with the highest betweeness centrality in descending order\n",
    "    '''\n",
    "    #use from_dic() to create a dataframe with the keys and vlaues of the bet_centrality object\n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'node': list(bet_centrality.keys()),\n",
    "        'between_centrality': list(bet_centrality.values())\n",
    "    })\n",
    "    #sort the values by centrality with descending order:\n",
    "    return df.sort_values('between_centrality', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cd06ed-68bc-4bf5-8454-cd72c306f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bet_cent = summary(Gnew)\n",
    "top_bet_cent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3cb9e9-7859-4e1d-b2f3-da302bfd6774",
   "metadata": {},
   "source": [
    "Subsetting the graphobject on the top 100 nodes with the highest in betweeness centrality meassure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ff9a5-76c6-4653-9402-369a1f4d9be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting the dataframe, keeping only the top 100 nodes with the highest betweenness centrality. \n",
    "topbet = top_bet_cent.iloc[0:100]\n",
    "topbet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8b90c-bcd7-4b1f-b180-59b30ab9af84",
   "metadata": {},
   "source": [
    "### Plotting the new graph object T. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4883ea-2c31-442f-b456-541f52c0952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new graph object as a subgraph og Gnew only with the top 100 nodes: \n",
    "topbet_nodes = topbet[\"node\"]\n",
    "T = Gnew.subgraph(topbet_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75adc6e6-18b3-4fad-b4d3-97dff4ff305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the new graph object:\n",
    "npos = nx.spring_layout(T, scale=1)\n",
    "fig = plt.figure(1, figsize=(30,30))\n",
    "nx.draw(T, pos=npos, node_color=\"seagreen\", with_labels = True, node_size=500, edge_color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5a666-8981-4f06-92d7-25bfcc9f90f9",
   "metadata": {},
   "source": [
    "Plotting the graphobject T with nodes size depending on the betweenness centrality meassure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322d9c8-5339-452b-b2aa-c42ec57cde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the betweenness centrality of the graph object T\n",
    "between_centrality_T = nx.betweenness_centrality(T)\n",
    "#plotting T with node_size depending on betweenness centrality\n",
    "npos = nx.spring_layout(T, scale=1)\n",
    "fig = plt.figure(1, figsize=(20,20))\n",
    "nx.draw(T, pos=npos, node_color=\"seagreen\", \n",
    "        node_size=[v * 10000 for v in between_centrality_T.values()], \n",
    "        #also adding labels\n",
    "        with_labels=True,\n",
    "        edge_color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67625d94-ddc4-41fd-908f-1f964bc14636",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining a function *find_node_with_highest_bet_cent* \n",
    "The function returns the nodes with the highest betweeness centrality in the graph G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33487934-1be6-432d-af42-635c82396877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find_node_with_highest_bet_cent()\n",
    "def find_node_with_highest_bet_cent(G):\n",
    "    '''returns the nodes with the highest betweeness centrality in the graph G.'''\n",
    "    # Computing betweenness centrality: bet_cent\n",
    "    bet_cent = nx.betweenness_centrality(G)\n",
    "    # Computing maximum betweenness centrality: max_bc\n",
    "    max_bc = max(list(bet_cent.values()))\n",
    "    nodes = set()\n",
    "    # Iterating over the betweenness centrality dictionary\n",
    "    for k, v in bet_cent.items():\n",
    "        # Checking if the current value has the maximum betweenness centrality\n",
    "        if v == max_bc:\n",
    "            # Adding the current node to the set of nodes\n",
    "            nodes.add(k)\n",
    "    return nodes\n",
    "\n",
    "# Using that function to find the node(s) that has the highest betweenness centrality in the network: top_bc\n",
    "top_bc = find_node_with_highest_bet_cent(Gnew)\n",
    "print(\"This is the node with the highest betweeness centrality: \",top_bc)\n",
    "\n",
    "# Assertion statement that checks that the node(s) is/are correctly identified.\n",
    "for node in top_bc:\n",
    "    assert nx.betweenness_centrality(Gnew)[node] == max(nx.betweenness_centrality(Gnew).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba683e-4bec-4029-85fe-6e864bc24def",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neihgbors of nodes\n",
    "Getting the degree of every nodes in the graph. Plotting a histogram of the degree centrality distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91688d94-fa45-48a5-8a31-70b31ce276f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the degree of every node: degrees\n",
    "degrees = [len(list(Gnew.neighbors(n))) for n in Gnew.nodes()]\n",
    "print(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d180ed-7ccb-4910-be34-be15a03769a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a histogram of the degree distribution of the graph\n",
    "plt.figure()\n",
    "plt.hist(degrees)\n",
    "plt.title(\"Histogram of the degree distribution of the graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed4ad4e-7dc5-478b-bb48-ecef4df6a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a scatter plot of the centrality distribution and the degree distribution\n",
    "plt.figure()\n",
    "plt.scatter(degrees, list(centrality.values()))\n",
    "plt.title(\"Scatter Plot of the centrality and the degree distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab89ac-141e-4c51-bef1-19205bd898ac",
   "metadata": {},
   "source": [
    "#### Defing the function *nodes_neighbors*\n",
    "The function *nodes_neighbors*  returns the count of neighbors the nodes have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8421c61-01b7-4839-8636-26db953d4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function nodes_neighbors\n",
    "def nodes_neighbors(G):\n",
    "    \"\"\"\n",
    "    Returns the count of neighbors the nodes in G have.\n",
    "    \"\"\"\n",
    "    nodes = set()\n",
    "    #iterate over all nodes in G\n",
    "    for n in G.nodes():\n",
    "        #counting the nodes and adding them to the set:\n",
    "        nodes.add(len(list(G.neighbors(n))))\n",
    "        \n",
    "    #return the neighbor of n\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ea22d-4ebf-4b82-9b59-343403f1cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = nodes_neighbors(Gnew)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c814879-6e1c-42e0-9e93-6057a3ee1fa9",
   "metadata": {},
   "source": [
    "#### Defining a functure *nodes_with_m_nrbs* \n",
    "The function return all nodes in a graph that have a soecific count of (m) neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf73162-63f3-49c7-a822-1e7b0ebc0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nodes_with_m_nbrs()\n",
    "def nodes_with_m_nbrs(G, m):\n",
    "    \"\"\"\n",
    "    Returns all nodes in graph G that have m neighbors.\n",
    "    \"\"\"\n",
    "    nodes = set()\n",
    "\n",
    "    # Iterate over all nodes in G\n",
    "    for n in G.nodes():\n",
    "\n",
    "        # Check if the number of neighbors of n matches m\n",
    "        if len(list(G.neighbors(n))) == m:\n",
    "\n",
    "            # Add the node n to the set\n",
    "            nodes.add(n)\n",
    "\n",
    "    # Return the nodes with m neighbors\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0af738-79da-4a6f-a613-f6f4e013cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print all nodes in Gnew that have 6 neighbors\n",
    "six_nbrs = nodes_with_m_nbrs(Gnew, 6)\n",
    "print(six_nbrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce6d6d5-8daf-4ed9-8ce0-533c3da42ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print all nodes in Gnew that have 72 neighbors\n",
    "seventytwo_nbrs = nodes_with_m_nbrs(Gnew, 72)\n",
    "print(seventytwo_nbrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7d94f-4cd7-4383-8b1c-f6b7396421b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if there realy is no node with 14 neighbors \n",
    "#(As the result shows when using the nodes_neighbors function on Gnew): \n",
    "fourteen_nbrs = nodes_with_m_nbrs(Gnew, 14)\n",
    "print(fourteen_nbrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b48c7-2989-4f7e-a8dd-fca488a1449b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Investigate Triangles in the graph\n",
    "Finding nodes that are involved in triangles. The API nx.triangles() returns a dictionary where the nodes are the keys and the values are the number of triangles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632da34-7523-4350-95c1-ef6c2aa5d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary with the triangles of nodes. \n",
    "triangles = nx.triangles(Gnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d1baf-c84a-462a-8433-2563ef1fa91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles.get(1)\n",
    "#nothing is return, there is no node with 1 triangle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32dd52-ba5e-4ed6-b22c-180b2b42032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles_values = list(triangles.values())\n",
    "print(sorted(triangles_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b001542-b6fe-486a-b9f8-ac87456a1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complicate way to find out if there are tringles. \n",
    "triangles_values = list(triangles.values())\n",
    "triangles2 = [i for i in triangles_values if i > 1]\n",
    "print(triangles2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decfdbe5-7ee1-4c78-a9cc-5ebab05c2862",
   "metadata": {},
   "source": [
    "There are no triangles in the graph object Gnew.Therefore tThe following function is not useful in this case, since there are no nodes in a triangle relationships.\n",
    "Code was: \n",
    "from itertools import combinations\n",
    "#Function that identifies all nodes in a triangle relationship.\n",
    "def nodes_in_triangle(G, n):\n",
    "    \"\"\"\n",
    "    Returns the nodes in a graph G that are involved in a triangle relationship.\n",
    "    \"\"\"\n",
    "    triangle_nodes = set([n])\n",
    "    # Iterating over all possible triangle relationship combinations\n",
    "    for n1, n2 in combinations(G.neighbors(n), 2):\n",
    "        # Checking if n1 and n2 have an edge between them\n",
    "        if G.has_edge(n1, n2) == True:\n",
    "            # Adding n1 to triangle_nodes\n",
    "            triangle_nodes.add(n1)\n",
    "            # Adding n2 to triangle_nodes\n",
    "            triangle_nodes.add(n2)\n",
    "    return triangle_nodes\n",
    "\n",
    "nodes_in_triangle(Gnew, 1)\n",
    "#shouldn't the result show at least two nodes? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685096e9-7a80-4ca5-a65b-41a94723281c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b9d5e2-f43e-43b1-a1ae-3607fba19449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding all cliques. not very informative in this case. Only holds pairs of two nodes. \n",
    "cliques = list(nx.find_cliques(Gnew))\n",
    "print(cliques[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbf3ad-fa23-491b-97ca-3ac24a22572d",
   "metadata": {},
   "source": [
    "##### Finding cliques.  \n",
    "cliques are \"groups of nodes that are fully connected to one another\", while a maximal clique is a clique that cannot be extended by adding another node in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2fb19-3638-47c1-8a3c-6e884514bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the cliques: \n",
    "cliques = nx.find_cliques(Gnew)\n",
    "cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c97ec-49f5-42e6-8468-356ffb258301",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", len(list(cliques)), \"cliques in the graph\")\n",
    "#why do I get the result 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffd5ee-145f-4c01-a83d-2eede18a5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_clique = sorted(nx.find_cliques(Gnew), key=lambda x:len(x))[-1]\n",
    "print(\"The largest clique constists of the nodes: \", largest_clique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec1267-3ea5-4872-aee2-3a39d2170a98",
   "metadata": {},
   "source": [
    "When the largest clique constits of only two nodes, there are no real cliques. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
